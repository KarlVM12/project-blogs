<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Karl Muller</title>
    <link>/</link>
    <description>Recent content in Home on Karl Muller</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Jan 2026 22:00:00 -0500</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Greater Expression does not Lead to Greater Quality</title>
      <link>/posts/greater-expression-not-greater-quality/</link>
      <pubDate>Tue, 20 Jan 2026 22:00:00 -0500</pubDate>
      
      <guid>/posts/greater-expression-not-greater-quality/</guid>
      <description>&lt;p&gt;Last year, I wrote a small piece on how &lt;a href=&#34;/posts/llms-are-expression-not-intelligence/&#34;&gt;LLMs = Expression, not Intelligence&lt;/a&gt;. I feel like now is a more important time than ever to revisit this thought. Not that it was wrong, precisely the opposite, but because that ability of expression and creation through these models has only continued to increase, have put even more amazing tools in the hands of so many people, but we have yet to see the so called proof of better engineered systems. In fact, most likely the opposite has occurred.&lt;/p&gt;</description>
      <content>&lt;p&gt;Last year, I wrote a small piece on how &lt;a href=&#34;/posts/llms-are-expression-not-intelligence/&#34;&gt;LLMs = Expression, not Intelligence&lt;/a&gt;. I feel like now is a more important time than ever to revisit this thought. Not that it was wrong, precisely the opposite, but because that ability of expression and creation through these models has only continued to increase, have put even more amazing tools in the hands of so many people, but we have yet to see the so called proof of better engineered systems. In fact, most likely the opposite has occurred.&lt;/p&gt;
&lt;p&gt;LLMs have yet to make an impact purely because the force multiplier aspect is only a force multiplier for those that use it correctly. For many, it still comes off as &amp;ldquo;slop&amp;rdquo; or slowing other people down. This has become especially evident in an age where so many people have stopped asking questions, or at least the right ones. Those who leverage LLMs correctly are those who are naturally curious, who are asking questions and actually wanting to learn. If LLMs to one are simply just a &amp;ldquo;do this task for me&amp;rdquo;, then you are never going to learn anything, and the LLM is probably going to give you an undesirable output, leading to your frustration.&lt;/p&gt;
&lt;p&gt;This is why with how explosive tools like Claude Code have become, we don&amp;rsquo;t see an explosion of better content. And this has been proven throughout history as well. Every time we have reached a milestone in greater expression, it has often times lead to the fear of worse quality, known as the &amp;ldquo;media panic cycle&amp;rdquo;, commonly seen recently with the spread of misinformation and even going back to &lt;a href=&#34;https://newlearningonline.com/literacies/chapter-1/socrates-on-the-forgetfulness-that-comes-with-writing&#34;&gt;Socrates&amp;rsquo; fear of forgetfulness from written language&lt;/a&gt; around 350 BCE.&lt;/p&gt;
&lt;p&gt;Today, we would be in the &lt;strong&gt;&lt;em&gt;AI panic cycle&lt;/em&gt;&lt;/strong&gt;, where each new model sparks some fear of jobs being replaced coupled with one&amp;rsquo;s degradation of their abilities (for those that use them improperly), even though these models should be increasing one&amp;rsquo;s expression and creativity.&lt;/p&gt;
&lt;p&gt;It often reminds me of the quote from Dijkstra&amp;rsquo;s &lt;a href=&#34;https://www.cs.utexas.edu/~EWD/transcriptions/EWD06xx/EWD667.html&#34;&gt;&amp;ldquo;On the foolishness of &amp;rsquo;natural language programming&amp;rsquo;&amp;rdquo;&lt;/a&gt; from 1978:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;although changing to communication between machine and man conducted in the latter&amp;rsquo;s native tongue would greatly increase the machine&amp;rsquo;s burden, we have to challenge the assumption that this would simplify man&amp;rsquo;s life&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Even though Dijkstra wrote this in 1978, it precisely defines the current state of natural language programming. Language Models have to compute an enormous amount of work and energy in order to utilize them via natural language. It gives us the ability to greatly express ourselves, but we have stopped learning and asking questions.&lt;/p&gt;
&lt;p&gt;All these tools have only proven more so that coding was never truly the skill, that the skill is in the engineer themselves, and the lengths they will go to improve themselves. The ones unaffected by the current AI panic cycle use these tools wisely, to be the advanced assistant for greater self expression they are supposed to be, not to replace their own effort, motivation, or thought.&lt;/p&gt;
&lt;p&gt;When the industry starts to preach this more than the &amp;ldquo;replace all developers&amp;rdquo; ideology, that is when we will truly start to see the benefits.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra, E. W. (1978). &lt;a href=&#34;https://www.cs.utexas.edu/~EWD/transcriptions/EWD06xx/EWD667.html&#34;&gt;On the foolishness of &amp;ldquo;natural language programming&amp;rdquo;&lt;/a&gt;. EWD667.&lt;/li&gt;
&lt;li&gt;Socrates on writing and memory (~350 BCE): &lt;a href=&#34;https://newlearningonline.com/literacies/chapter-1/socrates-on-the-forgetfulness-that-comes-with-writing&#34;&gt;The forgetfulness that comes with writing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Dimensions: A Terminal Tab Manager</title>
      <link>/posts/dimensions/</link>
      <pubDate>Fri, 02 Jan 2026 17:18:11 -0500</pubDate>
      
      <guid>/posts/dimensions/</guid>
      <description>&lt;p&gt;I built Dimensions because I kept losing momentum and navigability when working on multiple projects at once. Each project needs it own mix of tabs and switching between them with multiple projects starts to become a pain. Especially with so many new AI CLI tools alongside your running servers and editor, my terminal started to become a juggling act. Dimensions wraps tmux with a fast, visual TUI that keeps my workflows organized as named dimensions so you can move between projects and contexts much easier.&lt;/p&gt;</description>
      <content>&lt;p&gt;I built Dimensions because I kept losing momentum and navigability when working on multiple projects at once. Each project needs it own mix of tabs and switching between them with multiple projects starts to become a pain. Especially with so many new AI CLI tools alongside your running servers and editor, my terminal started to become a juggling act. Dimensions wraps tmux with a fast, visual TUI that keeps my workflows organized as named dimensions so you can move between projects and contexts much easier.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/KarlVM12/Dimensions&#34;&gt;Dimensions on GitHub ↗&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/1e1b98ad-1e43-4156-9767-d1b2b212e1cf&#34; alt=&#34;Dimensions Screenshot&#34;&gt;&lt;/p&gt;
&lt;p&gt;What it does well:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group tabs into named dimensions and switch contexts instantly&lt;/li&gt;
&lt;li&gt;Keep processes alive in the background when you swap dimensions&lt;/li&gt;
&lt;li&gt;Fuzzy search across dimensions and tabs for quick navigation&lt;/li&gt;
&lt;li&gt;Persist dimension names, tabs, and commands to disk&lt;/li&gt;
&lt;li&gt;Launch as a tmux popup with a single keybind&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you want to try it, the project lives here: &lt;a href=&#34;https://github.com/KarlVM12/Dimensions&#34;&gt;Dimensions on GitHub&lt;/a&gt;. It is written in Rust with ratatui and leans on tmux for session management.&lt;/p&gt;
&lt;p&gt;Quick install:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -fsSL https://raw.githubusercontent.com/KarlVM12/Dimensions/master/install.sh | sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And if you want the popup workflow, add this to &lt;code&gt;~/.tmux.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bind -n C-g display-popup -E -w 80% -h 80% &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dimensions&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you do give it a shot, I would love to hear what you want to see next.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Grammar Aware Language Models</title>
      <link>/posts/grammar-aware-language-models/</link>
      <pubDate>Tue, 16 Dec 2025 21:30:00 -0500</pubDate>
      
      <guid>/posts/grammar-aware-language-models/</guid>
      <description>&lt;p&gt;Large language models (LLMs) demonstrate emergent and strong grammatical fluency, but can still violate the constraints of a language&amp;rsquo;s grammar such as in code generation or formal reasoning. We investigate whether an explicit, lightweight grammar prior can improve syntactic correctness without modifying the weights of the model itself.&lt;/p&gt;
&lt;p&gt;We propose a grammar aware scoring framework that augments an LLM&amp;rsquo;s sentence log-likelihood with a part of speech (POS) bigram priors model trained on tagged text. The resulting model acts similar to a product of experts, combining the semantic likelihood of a sentence from the LLM with the grammar structural plausibility of that sentence from the POS model.&lt;/p&gt;</description>
      <content>&lt;p&gt;Large language models (LLMs) demonstrate emergent and strong grammatical fluency, but can still violate the constraints of a language&amp;rsquo;s grammar such as in code generation or formal reasoning. We investigate whether an explicit, lightweight grammar prior can improve syntactic correctness without modifying the weights of the model itself.&lt;/p&gt;
&lt;p&gt;We propose a grammar aware scoring framework that augments an LLM&amp;rsquo;s sentence log-likelihood with a part of speech (POS) bigram priors model trained on tagged text. The resulting model acts similar to a product of experts, combining the semantic likelihood of a sentence from the LLM with the grammar structural plausibility of that sentence from the POS model.&lt;/p&gt;
&lt;p&gt;We evaluate this approach on the BLiMP benchmark of minimal grammatical pairs. Our results show that POS based priors consistently improve performance on several syntactic structures found in formal language (e.g. subject-verb agreement, intransitives, irregular past participles) while occasionally degrading complex structures (e.g. negative polarity items, principle A). Overall, we find that grammar priors are most effective when applied selectively, highlighting both the promise and limitation of a simple, shallow grammatical bias.&lt;/p&gt;
&lt;h2 id=&#34;key-findings&#34;&gt;Key Findings&lt;/h2&gt;
&lt;p&gt;Our experiments revealed several important insights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Local Dependencies&lt;/strong&gt;: POS bigram priors significantly improved performance on syntactic structures governed by local regularities, including subject-verb agreement (+2.3%), wh-movement (+5.9%), and irregular past participle verbs (+6.8%).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical Limitations&lt;/strong&gt;: The approach degraded performance on constructions requiring hierarchical or semantic understanding, such as Principle A binding (-7.0%) and negative polarity item licensing (-3.9%).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Selective Application&lt;/strong&gt;: A single global grammar weight applied uniformly across all syntactic structures proved suboptimal, suggesting the need for adaptive, context-aware grammar priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;implications&#34;&gt;Implications&lt;/h2&gt;
&lt;p&gt;This work demonstrates that even simple grammatical abstractions can complement large language models when applied selectively. The product-of-experts framework offers a flexible alternative to hard grammar-constrained decoding, preserving the original token space while avoiding model retraining. However, the limitations of POS bigram models highlight the need for richer syntactic representations, such as dependency-aware grammar priors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Read the full paper:&lt;/strong&gt; &lt;a href=&#34;https://ts8labs.com/research&#34;&gt;https://ts8labs.com/research&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Research conducted at Cornell Tech&lt;/em&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Language &amp; LLMs = Expression, not Intelligence</title>
      <link>/posts/llms-are-expression-not-intelligence/</link>
      <pubDate>Sun, 04 May 2025 17:54:46 -0400</pubDate>
      
      <guid>/posts/llms-are-expression-not-intelligence/</guid>
      <description>&lt;p&gt;LLMs have been lauded for having intelligence and reasoning capabilities simply from choosing the next probable word in a sequence &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;.
Formally, the APA defines intelligence as &amp;ldquo;the ability to derive information, learn from experience, adapt to the environment, understand, and correctly utilize thought and reason.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Language is certainly a powerful tool for communicating, spreading ideas, and technological advancement. Without language, ideas could never have moved as fast as they currently do. With this, some would then deduce that language then inherently leads towards intelligence, but this is simply not true. I do not study quantum mechanics, but I can read, memorize, and recite a proof if given enough to read, enough time to memorize, and a medium in order to regurgitate the information (speaking/writing English in this case). But that in no means actually proves I am intelligent or understand what I am saying or writing. With enough different sources of information and time to put it all together, I could probably also string together different memorized pieces of information to reach another piece of information, without ever having to actually understand any of it. In Searle&amp;rsquo;s Chinese Room Argument, a person inside a room can manipulate Chinese symbols following rules without ever actually understanding Chinese &lt;a href=&#34;#ref2&#34;&gt;[2]&lt;/a&gt;. This shows how language &amp;amp; syntax is not equal to semantics and understanding.&lt;/p&gt;</description>
      <content>&lt;p&gt;LLMs have been lauded for having intelligence and reasoning capabilities simply from choosing the next probable word in a sequence &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;.
Formally, the APA defines intelligence as &amp;ldquo;the ability to derive information, learn from experience, adapt to the environment, understand, and correctly utilize thought and reason.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Language is certainly a powerful tool for communicating, spreading ideas, and technological advancement. Without language, ideas could never have moved as fast as they currently do. With this, some would then deduce that language then inherently leads towards intelligence, but this is simply not true. I do not study quantum mechanics, but I can read, memorize, and recite a proof if given enough to read, enough time to memorize, and a medium in order to regurgitate the information (speaking/writing English in this case). But that in no means actually proves I am intelligent or understand what I am saying or writing. With enough different sources of information and time to put it all together, I could probably also string together different memorized pieces of information to reach another piece of information, without ever having to actually understand any of it. In Searle&amp;rsquo;s Chinese Room Argument, a person inside a room can manipulate Chinese symbols following rules without ever actually understanding Chinese &lt;a href=&#34;#ref2&#34;&gt;[2]&lt;/a&gt;. This shows how language &amp;amp; syntax is not equal to semantics and understanding.&lt;/p&gt;
&lt;p&gt;When we apply this to LLMs, we can see this is also true. With enough time to train and tweak their parameters, weights, and biases, they can generate that information in their own medium. Once again, however, this does not equate to intelligence with the same following as the previous conclusion. Language in all cases serves only as a medium to transmit information and ideas, as a means of expression. LLMs can express and perform what some call ‘reasoning’ (explored below) across as many ideas as they want, but that in no way proceeds to assume intelligence, and especially far from Artificial Intelligence.&lt;/p&gt;
&lt;p&gt;Since we can see language as a means of expression simply does not, and can not by itself, lead to understanding, there is also the topic of tackling what is currently called ‘reasoning’ in the AI hype zeitgeist. Reasoning as it currently works in LLMs string together the next most probable strings of text based on its training, as well as throwing a couple of tricks in. Adding these tricks does not mean it is actually reasoning by any means. This perceived &amp;lsquo;reasoning&amp;rsquo; only exists simply because people were extending the also misnomer of &lt;em&gt;Chain of Thought&lt;/em&gt;. There might be a chain of words being strung together, but no thought process is actually occurring. For example, a simple trick of inserting ‘Let&amp;rsquo;s think step by step’ in the sequence of probabilities has resulted in an increased retrieval of a correct answer in LLMs &lt;a href=&#34;#ref3&#34;&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is of course why prompt engineering works so well. If you insert a token of doubt into an incorrect answer, it will lean the probability towards a more correct answer. Since each token influences the conditional probability of the next, adjusting earlier tokens can shift the model’s output distribution toward more probable completions, and less towards &amp;lsquo;hallucinations&amp;rsquo;, as the anthropomorphized term goes. Therefore, when you throw a ‘wait’ &lt;a href=&#34;#ref4&#34;&gt;[4]&lt;/a&gt; in the following sequence, it leans even further in towards what would be the most correct probability according to its training. Tricks like these are by no means reasoning. Stringing together more probabilities will of course lead to improved retrieval because you start to touch on more of the parameters and tokens associated with the prompt. With more context and tokens surrounding a prompt, after all the so called ‘reasoning’ process, that will inherently lead to a better answer. So there is no actual reasoning going on, just more compute and tokens leveraged with a trick being spit out to reach that final answer.&lt;/p&gt;
&lt;p&gt;To round this out, language does not equate to understanding, and is far from intelligence. Regurgitating and retrieving more information about a topic does not make one intelligent, as well as how the ‘reasoning’ associated with current LLMs does not. Googling something does not mean I know what I am talking about. Misnomers, marketing, and anthropomorphizing is what have led to this hype of &amp;lsquo;intelligence&amp;rsquo; in the first place. I am in no means downplaying the technological ability of LLMs, just defining it into a more correct category. LLMs have vastly improved productivity in many areas, albeit sacrificed for actual learning and understanding. They are a great tool for retrieval, search, summary, and any means of expression in general, but could in no means have the capacity to recognize, solve, and understand problems and replace humans with actual intelligence. We are in the midst of a revolution of expression, where people can spread, articulate, and prototype ideas, images, stories, and more faster than ever before. Let’s just make sure we don’t let ourselves be captivated by creative language masking as intelligence like some already are in other spheres of life.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;h6 id=&#34;ref1&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[1] Marcus, Gary, and Ernest Davis. GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about. MIT Technology Review, 2020.
&lt;a href=&#34;https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/&#34;&gt;https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;ref2&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[2] Searle, John. &amp;ldquo;Minds, brains, and programs.&amp;rdquo; Behavioral and Brain Sciences 3.3 (1980): 417–457.&lt;/p&gt;
&lt;h6 id=&#34;ref3&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[3] Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &amp;amp; Iwasawa, Y. (2022). &lt;em&gt;Large Language Models are Zero-Shot Reasoners&lt;/em&gt;. arXiv preprint arXiv:2205.11916. &lt;a href=&#34;https://arxiv.org/pdf/2205.11916&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;ref4&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[4] Muennighoff, N., Yang, Z., Shi, W., Li, X. L., Fei-Fei, L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Candès, E., &amp;amp; Hashimoto, T. (2025). &lt;em&gt;s1: Simple test-time scaling&lt;/em&gt;. arXiv preprint arXiv:2501.19393. &lt;a href=&#34;https://arxiv.org/pdf/2501.19393&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Ghostty Nvim Config</title>
      <link>/posts/ghostty-nvim-config/</link>
      <pubDate>Sat, 18 Jan 2025 23:58:58 -0500</pubDate>
      
      <guid>/posts/ghostty-nvim-config/</guid>
      <description>&lt;p&gt;The Primeagen inspired me to start looking into better developer tools and actually start using nvim. Now I have adapted to ghostty and nvim and have come to really like it. Therefore, just want to document my config for when I switch devices or if anyone else actually happens to be interested. I could repeat myself here, but all you need is in my github repo &lt;a href=&#34;https://github.com/KarlVM12/ghostty-nvim-config&#34;&gt;ghostty-nvim-config&lt;/a&gt;.&lt;/p&gt;</description>
      <content>&lt;p&gt;The Primeagen inspired me to start looking into better developer tools and actually start using nvim. Now I have adapted to ghostty and nvim and have come to really like it. Therefore, just want to document my config for when I switch devices or if anyone else actually happens to be interested. I could repeat myself here, but all you need is in my github repo &lt;a href=&#34;https://github.com/KarlVM12/ghostty-nvim-config&#34;&gt;ghostty-nvim-config&lt;/a&gt;.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
