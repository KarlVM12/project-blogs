<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Karl Muller</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Karl Muller</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Jan 2026 17:18:11 -0500</lastBuildDate><atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dimensions: A Terminal Tab Manager</title>
      <link>/posts/dimensions/</link>
      <pubDate>Fri, 02 Jan 2026 17:18:11 -0500</pubDate>
      
      <guid>/posts/dimensions/</guid>
      <description>&lt;p&gt;I built Dimensions because I kept losing momentum and navigability when working on multiple projects at once. Each project needs it own mix of tabs and switching between them with multiple projects starts to become a pain. Especially with so many new AI CLI tools alongside your running servers and editor, my terminal started to become a juggling act. Dimensions wraps tmux with a fast, visual TUI that keeps my workflows organized as named dimensions so you can move between projects and contexts much easier.&lt;/p&gt;</description>
      <content>&lt;p&gt;I built Dimensions because I kept losing momentum and navigability when working on multiple projects at once. Each project needs it own mix of tabs and switching between them with multiple projects starts to become a pain. Especially with so many new AI CLI tools alongside your running servers and editor, my terminal started to become a juggling act. Dimensions wraps tmux with a fast, visual TUI that keeps my workflows organized as named dimensions so you can move between projects and contexts much easier.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/1e1b98ad-1e43-4156-9767-d1b2b212e1cf&#34; alt=&#34;Dimensions Screenshot&#34;&gt;&lt;/p&gt;
&lt;p&gt;What it does well:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group tabs into named dimensions and switch contexts instantly&lt;/li&gt;
&lt;li&gt;Keep processes alive in the background when you swap dimensions&lt;/li&gt;
&lt;li&gt;Fuzzy search across dimensions and tabs for quick navigation&lt;/li&gt;
&lt;li&gt;Persist dimension names, tabs, and commands to disk&lt;/li&gt;
&lt;li&gt;Launch as a tmux popup with a single keybind&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you want to try it, the project lives here: &lt;a href=&#34;https://github.com/KarlVM12/Dimensions&#34;&gt;Dimensions on GitHub&lt;/a&gt;. It is written in Rust with ratatui and leans on tmux for session management.&lt;/p&gt;
&lt;p&gt;Quick install:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -fsSL https://raw.githubusercontent.com/KarlVM12/Dimensions/master/install.sh | sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And if you want the popup workflow, add this to &lt;code&gt;~/.tmux.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bind -n C-g display-popup -E -w 80% -h 80% &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dimensions&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you do give it a shot, I would love to hear what you want to see next.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Grammar Aware Language Models</title>
      <link>/posts/grammar-aware-language-models/</link>
      <pubDate>Tue, 16 Dec 2025 21:30:00 -0500</pubDate>
      
      <guid>/posts/grammar-aware-language-models/</guid>
      <description>&lt;p&gt;Large language models (LLMs) demonstrate emergent and strong grammatical fluency, but can still violate the constraints of a language&amp;rsquo;s grammar such as in code generation or formal reasoning. We investigate whether an explicit, lightweight grammar prior can improve syntactic correctness without modifying the weights of the model itself.&lt;/p&gt;
&lt;p&gt;We propose a grammar aware scoring framework that augments an LLM&amp;rsquo;s sentence log-likelihood with a part of speech (POS) bigram priors model trained on tagged text. The resulting model acts similar to a product of experts, combining the semantic likelihood of a sentence from the LLM with the grammar structural plausibility of that sentence from the POS model.&lt;/p&gt;</description>
      <content>&lt;p&gt;Large language models (LLMs) demonstrate emergent and strong grammatical fluency, but can still violate the constraints of a language&amp;rsquo;s grammar such as in code generation or formal reasoning. We investigate whether an explicit, lightweight grammar prior can improve syntactic correctness without modifying the weights of the model itself.&lt;/p&gt;
&lt;p&gt;We propose a grammar aware scoring framework that augments an LLM&amp;rsquo;s sentence log-likelihood with a part of speech (POS) bigram priors model trained on tagged text. The resulting model acts similar to a product of experts, combining the semantic likelihood of a sentence from the LLM with the grammar structural plausibility of that sentence from the POS model.&lt;/p&gt;
&lt;p&gt;We evaluate this approach on the BLiMP benchmark of minimal grammatical pairs. Our results show that POS based priors consistently improve performance on several syntactic structures found in formal language (e.g. subject-verb agreement, intransitives, irregular past participles) while occasionally degrading complex structures (e.g. negative polarity items, principle A). Overall, we find that grammar priors are most effective when applied selectively, highlighting both the promise and limitation of a simple, shallow grammatical bias.&lt;/p&gt;
&lt;h2 id=&#34;key-findings&#34;&gt;Key Findings&lt;/h2&gt;
&lt;p&gt;Our experiments revealed several important insights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Local Dependencies&lt;/strong&gt;: POS bigram priors significantly improved performance on syntactic structures governed by local regularities, including subject-verb agreement (+2.3%), wh-movement (+5.9%), and irregular past participle verbs (+6.8%).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical Limitations&lt;/strong&gt;: The approach degraded performance on constructions requiring hierarchical or semantic understanding, such as Principle A binding (-7.0%) and negative polarity item licensing (-3.9%).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Selective Application&lt;/strong&gt;: A single global grammar weight applied uniformly across all syntactic structures proved suboptimal, suggesting the need for adaptive, context-aware grammar priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;implications&#34;&gt;Implications&lt;/h2&gt;
&lt;p&gt;This work demonstrates that even simple grammatical abstractions can complement large language models when applied selectively. The product-of-experts framework offers a flexible alternative to hard grammar-constrained decoding, preserving the original token space while avoiding model retraining. However, the limitations of POS bigram models highlight the need for richer syntactic representations, such as dependency-aware grammar priors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Read the full paper:&lt;/strong&gt; &lt;a href=&#34;https://ts8labs.com/research&#34;&gt;https://ts8labs.com/research&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Research conducted at Cornell Tech&lt;/em&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Language &amp; LLMs = Expression, not Intelligence</title>
      <link>/posts/llms-are-expression-not-intelligence/</link>
      <pubDate>Sun, 04 May 2025 17:54:46 -0400</pubDate>
      
      <guid>/posts/llms-are-expression-not-intelligence/</guid>
      <description>&lt;p&gt;LLMs have been lauded for having intelligence and reasoning capabilities simply from choosing the next probable word in a sequence &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;.
Formally, the APA defines intelligence as &amp;ldquo;the ability to derive information, learn from experience, adapt to the environment, understand, and correctly utilize thought and reason.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Language is certainly a powerful tool for communicating, spreading ideas, and technological advancement. Without language, ideas could never have moved as fast as they currently do. With this, some would then deduce that language then inherently leads towards intelligence, but this is simply not true. I do not study quantum mechanics, but I can read, memorize, and recite a proof if given enough to read, enough time to memorize, and a medium in order to regurgitate the information (speaking/writing English in this case). But that in no means actually proves I am intelligent or understand what I am saying or writing. With enough different sources of information and time to put it all together, I could probably also string together different memorized pieces of information to reach another piece of information, without ever having to actually understand any of it. In Searle&amp;rsquo;s Chinese Room Argument, a person inside a room can manipulate Chinese symbols following rules without ever actually understanding Chinese &lt;a href=&#34;#ref2&#34;&gt;[2]&lt;/a&gt;. This shows how language &amp;amp; syntax is not equal to semantics and understanding.&lt;/p&gt;</description>
      <content>&lt;p&gt;LLMs have been lauded for having intelligence and reasoning capabilities simply from choosing the next probable word in a sequence &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;.
Formally, the APA defines intelligence as &amp;ldquo;the ability to derive information, learn from experience, adapt to the environment, understand, and correctly utilize thought and reason.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Language is certainly a powerful tool for communicating, spreading ideas, and technological advancement. Without language, ideas could never have moved as fast as they currently do. With this, some would then deduce that language then inherently leads towards intelligence, but this is simply not true. I do not study quantum mechanics, but I can read, memorize, and recite a proof if given enough to read, enough time to memorize, and a medium in order to regurgitate the information (speaking/writing English in this case). But that in no means actually proves I am intelligent or understand what I am saying or writing. With enough different sources of information and time to put it all together, I could probably also string together different memorized pieces of information to reach another piece of information, without ever having to actually understand any of it. In Searle&amp;rsquo;s Chinese Room Argument, a person inside a room can manipulate Chinese symbols following rules without ever actually understanding Chinese &lt;a href=&#34;#ref2&#34;&gt;[2]&lt;/a&gt;. This shows how language &amp;amp; syntax is not equal to semantics and understanding.&lt;/p&gt;
&lt;p&gt;When we apply this to LLMs, we can see this is also true. With enough time to train and tweak their parameters, weights, and biases, they can generate that information in their own medium. Once again, however, this does not equate to intelligence with the same following as the previous conclusion. Language in all cases serves only as a medium to transmit information and ideas, as a means of expression. LLMs can express and perform what some call ‘reasoning’ (explored below) across as many ideas as they want, but that in no way proceeds to assume intelligence, and especially far from Artificial Intelligence.&lt;/p&gt;
&lt;p&gt;Since we can see language as a means of expression simply does not, and can not by itself, lead to understanding, there is also the topic of tackling what is currently called ‘reasoning’ in the AI hype zeitgeist. Reasoning as it currently works in LLMs string together the next most probable strings of text based on its training, as well as throwing a couple of tricks in. Adding these tricks does not mean it is actually reasoning by any means. This perceived &amp;lsquo;reasoning&amp;rsquo; only exists simply because people were extending the also misnomer of &lt;em&gt;Chain of Thought&lt;/em&gt;. There might be a chain of words being strung together, but no thought process is actually occurring. For example, a simple trick of inserting ‘Let&amp;rsquo;s think step by step’ in the sequence of probabilities has resulted in an increased retrieval of a correct answer in LLMs &lt;a href=&#34;#ref3&#34;&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is of course why prompt engineering works so well. If you insert a token of doubt into an incorrect answer, it will lean the probability towards a more correct answer. Since each token influences the conditional probability of the next, adjusting earlier tokens can shift the model’s output distribution toward more probable completions, and less towards &amp;lsquo;hallucinations&amp;rsquo;, as the anthropomorphized term goes. Therefore, when you throw a ‘wait’ &lt;a href=&#34;#ref4&#34;&gt;[4]&lt;/a&gt; in the following sequence, it leans even further in towards what would be the most correct probability according to its training. Tricks like these are by no means reasoning. Stringing together more probabilities will of course lead to improved retrieval because you start to touch on more of the parameters and tokens associated with the prompt. With more context and tokens surrounding a prompt, after all the so called ‘reasoning’ process, that will inherently lead to a better answer. So there is no actual reasoning going on, just more compute and tokens leveraged with a trick being spit out to reach that final answer.&lt;/p&gt;
&lt;p&gt;To round this out, language does not equate to understanding, and is far from intelligence. Regurgitating and retrieving more information about a topic does not make one intelligent, as well as how the ‘reasoning’ associated with current LLMs does not. Googling something does not mean I know what I am talking about. Misnomers, marketing, and anthropomorphizing is what have led to this hype of &amp;lsquo;intelligence&amp;rsquo; in the first place. I am in no means downplaying the technological ability of LLMs, just defining it into a more correct category. LLMs have vastly improved productivity in many areas, albeit sacrificed for actual learning and understanding. They are a great tool for retrieval, search, summary, and any means of expression in general, but could in no means have the capacity to recognize, solve, and understand problems and replace humans with actual intelligence. We are in the midst of a revolution of expression, where people can spread, articulate, and prototype ideas, images, stories, and more faster than ever before. Let’s just make sure we don’t let ourselves be captivated by creative language masking as intelligence like some already are in other spheres of life.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;h6 id=&#34;ref1&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[1] Marcus, Gary, and Ernest Davis. GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about. MIT Technology Review, 2020.
&lt;a href=&#34;https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/&#34;&gt;https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;ref2&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[2] Searle, John. &amp;ldquo;Minds, brains, and programs.&amp;rdquo; Behavioral and Brain Sciences 3.3 (1980): 417–457.&lt;/p&gt;
&lt;h6 id=&#34;ref3&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[3] Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &amp;amp; Iwasawa, Y. (2022). &lt;em&gt;Large Language Models are Zero-Shot Reasoners&lt;/em&gt;. arXiv preprint arXiv:2205.11916. &lt;a href=&#34;https://arxiv.org/pdf/2205.11916&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;ref4&#34;&gt;&lt;/h6&gt;
&lt;p&gt;[4] Muennighoff, N., Yang, Z., Shi, W., Li, X. L., Fei-Fei, L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Candès, E., &amp;amp; Hashimoto, T. (2025). &lt;em&gt;s1: Simple test-time scaling&lt;/em&gt;. arXiv preprint arXiv:2501.19393. &lt;a href=&#34;https://arxiv.org/pdf/2501.19393&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Ghostty Nvim Config</title>
      <link>/posts/ghostty-nvim-config/</link>
      <pubDate>Sat, 18 Jan 2025 23:58:58 -0500</pubDate>
      
      <guid>/posts/ghostty-nvim-config/</guid>
      <description>&lt;p&gt;The Primeagen inspired me to start looking into better developer tools and actually start using nvim. Now I have adapted to ghostty and nvim and have come to really like it. Therefore, just want to document my config for when I switch devices or if anyone else actually happens to be interested. I could repeat myself here, but all you need is in my github repo &lt;a href=&#34;https://github.com/KarlVM12/ghostty-nvim-config&#34;&gt;ghostty-nvim-config&lt;/a&gt;.&lt;/p&gt;</description>
      <content>&lt;p&gt;The Primeagen inspired me to start looking into better developer tools and actually start using nvim. Now I have adapted to ghostty and nvim and have come to really like it. Therefore, just want to document my config for when I switch devices or if anyone else actually happens to be interested. I could repeat myself here, but all you need is in my github repo &lt;a href=&#34;https://github.com/KarlVM12/ghostty-nvim-config&#34;&gt;ghostty-nvim-config&lt;/a&gt;.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Dynamic Probabilistic Mapping Model</title>
      <link>/posts/dpmm/</link>
      <pubDate>Wed, 08 Jan 2025 22:50:20 -0500</pubDate>
      
      <guid>/posts/dpmm/</guid>
      <description>&lt;p&gt;Accurate classification across diverse domains is essential for information decision-making and effective resource allocation. With this, comes the Dynamic Probabilistic Mapping Model (DPMM), a flexible hierachial framework designed for multidomain predictions by analyzing feature-outcome correlations. DPMM employs a two-tiered architecture: a primary model initially categorizes each conclusion separately using one-hot encoded features mapped through probabilistic distributions. To address misclassifications and overlapping characteristics, the framework dynamically merges related classes based on performance metrics derived from confusion matrix analysis, and subsequently deploys specialized subclass models for refined predictions.&lt;/p&gt;</description>
      <content>&lt;p&gt;Accurate classification across diverse domains is essential for information decision-making and effective resource allocation. With this, comes the Dynamic Probabilistic Mapping Model (DPMM), a flexible hierachial framework designed for multidomain predictions by analyzing feature-outcome correlations. DPMM employs a two-tiered architecture: a primary model initially categorizes each conclusion separately using one-hot encoded features mapped through probabilistic distributions. To address misclassifications and overlapping characteristics, the framework dynamically merges related classes based on performance metrics derived from confusion matrix analysis, and subsequently deploys specialized subclass models for refined predictions.&lt;/p&gt;
&lt;p&gt;This hierarchial approach enables DPMM to adapt to varying data distributions and feature interactions, enhancing classification accuracy and reliability across multiple application areas such as healthcare, finance, and cybersecurity, allowing for the creation of domain specific AI agents. For instance, in an example healthcare scenario, the primary model achieved an initial accuracy of approximately 76% which can improve to around 87% after merging related classes. Subclass models further refine predictions, significantly boosting accuracy for specific condition groups. These results exemplify DPMM&amp;rsquo;s capability to continuously optimize its structure based on input data and outcome distributions. By integrating probabilistic feature mappings with dynamic class restructing, DPMM offers a robust and scalable solution for complex multi-class prediction tasks, ensuring higher precision and adaptability in diverse real-world applications.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
